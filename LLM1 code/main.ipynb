{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-11 17:20:29.604708: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-11 17:20:29.642060: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-11 17:20:29.642079: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-11 17:20:29.643236: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-11 17:20:29.650270: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-11 17:20:30.399416: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import collections\n",
    "from torch import nn\n",
    "from utils.finetune import Fine_tune\n",
    "from configs.Fine_tune_config import *\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['batch_size', 'micro_batch_size', 'num_epochs', 'learning_rate', 'cutoff_len', 'val_set_size', 'resume_from_checkpoint', 'prompt_template_name', 'warmup_steps', 'eval_steps', 'save_steps', 'save_total_limit', 'lora_r', 'lora_alpha', 'lora_dropout', 'lora_target_modules', 'train_on_inputs', 'add_eos_token', 'group_by_length', 'wandb_project', 'wandb_run_name', 'wandb_watch', 'wandb_log_model'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Configs.keys()\n",
    "hebing = {}\n",
    "for Key,Value in Configs.items():\n",
    "    # 将所有key对应的value合并为1个字典\n",
    "    for key,value in Value.items():\n",
    "        hebing[key] = value\n",
    "hebing.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从默认值进行更改\n",
    "# ccc = {'num_train_epochs' : 6,'learning_rate' : 9e-4,'ttt':1}\n",
    "       \n",
    "# test = Fine_tune(train_data_path='./Train/Dataset/SET-2024_1_1/Train_Set/Train_Set.json',**hebing)\n",
    "# p = test.train(**ccc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Configuration\n",
      "--------------------------------------\n",
      "base_model: meta-llama/Llama-2-7b-hf\n",
      "data_path: /root/autodl-tmp/new_version/train_set_fixed.json\n",
      "output_dir: ./Train/Output/2024-08-11/17-20\n",
      "prompt_template_name: alpaca\n",
      "--------------------------------------\n",
      "load_in_8bit: True\n",
      "torch_dtype: torch.float16\n",
      "device_map: auto\n",
      "--------------------------------------\n",
      "lora_r: 16\n",
      "lora_alpha: 32\n",
      "lora_dropout: 0.05\n",
      "lora_target_modules: ['q_proj', 'v_proj']\n",
      "--------------------------------------\n",
      "batch_size: 128\n",
      "micro_batch_size: 4\n",
      "gradient_accumulation_steps: 32\n",
      "num_epochs: 3\n",
      "learning_rate: 0.0003\n",
      "cutoff_len: 256\n",
      "val_set_size: 200\n",
      "train_on_inputs: True\n",
      "add_eos_token: False\n",
      "group_by_length: False\n",
      "resume_from_checkpoint: None\n",
      "ddp: False\n",
      "warmup_steps: 100\n",
      "eval_steps: 20\n",
      "save_steps: 20\n",
      "save_total_limit: 5\n",
      "--------------------------------------\n",
      "wandb_project: test\n",
      "wandb_run_name: \n",
      "wandb_watch: \n",
      "wandb_log_model: \n",
      "--------------------------------------\n",
      "tokenizer_name: meta-llama/Llama-2-7b-hf\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test = Fine_tune(train_data_path='/root/autodl-tmp/new_version/train_set_fixed.json',**hebing)\n",
    "#test = Fine_tune(train_data_path='./Dataset/Small_Set/Set_Second/Standrd_Set/Train_Set/Train_Set.json',**hebing)\n",
    "test.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Tokenizer : \"meta-llama/Llama-2-7b-hf\"\n",
      "Tokenizer: meta-llama/Llama-2-7b-hf Loaded Successfully\n",
      "\n",
      "Change config of the tokenizer.\n",
      "Loading the default tokenizer configuration.\n",
      "pad_token_id\n",
      "padding_side\n",
      "      Parameter Value\n",
      "0  pad_token_id     0\n",
      "1  padding_side  left\n",
      "\n",
      "Beginning token : <s> , Beginning token id : 1 \n",
      "\n",
      "Ending token : </s> , Ending token id : 2 \n",
      "\n",
      "Padding token : <unk> , Padding token id : 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_tokenizer = test.load_tokenizer(change_tokenizer=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default template : alpaca\n",
      "Template Loaded Successfully\n",
      "/root/autodl-tmp/new_version/train_set_fixed.json\n"
     ]
    }
   ],
   "source": [
    "test.load_template()\n",
    "dataset = test.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing done.\n",
      "{'Output': {'Entity1:Object': 'potato powders', 'Entity2:Spectrum': 'else', 'Question_type': 'Random questions'}, 'Instruction': \"Instruction: Please extract the research object entities and spectral types used in the input questions, and classify the types of questions.The types of questions are: 1. Spectral Detection Method 2. Feature Processing Method 3. Machine learning Method 4. Evaluated metrics 5. Random questions.\\n For the input questions which belongs to the type of Spectral Detection Method, the spectral types extracted should be 'not found'.\", 'Input': 'Question:How can the impact of processing methods on chemical compositions in potatoes be further explored using the H-1 NMR spectrum mentioned in the research?'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a8c78c154b40aeb5056c2acb4a1da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c8f46005314337b239c3f6b795e273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "has input\n",
      "Data Mapped Successfully\n"
     ]
    }
   ],
   "source": [
    "preprocess_dataset = test.preprocess(dataset)\n",
    "print(preprocess_dataset['Train'][0])\n",
    "train_data,valid_data = test.map_dataset(preprocess_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model : \"meta-llama/Llama-2-7b-hf\"\n",
      "{'device_map': 'auto', 'load_in_8bit': True, 'torch_dtype': torch.float16}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de97fef4a4314f3a81d751a654e6132b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: meta-llama/Llama-2-7b-hf --- Loaded Successfully\n"
     ]
    }
   ],
   "source": [
    "model = test.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/peft/utils/other.py:122: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 8,388,608 || all params: 6,746,804,224 || trainable%: 0.12433454005023165\n",
      "Model Prepared Successfully\n"
     ]
    }
   ],
   "source": [
    "change_lora_config = {'lora_r':16,'lora_alpha':32,'lora_target_modules':['q_proj', 'v_proj']} # The default config is : 'lora_r':8,'lora_alpha':16. You can change it by passing a dict to the function.\n",
    "LORA_config = test.model_prepare(\n",
    "    lora_config=change_lora_config\n",
    "    )\n",
    "#LORA_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mljhsysu46\u001b[0m (\u001b[33mlakestar\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/autodl-tmp/new_version/wandb/run-20240811_172106-umrimeso</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lakestar/text_spectral_analysis/runs/umrimeso' target=\"_blank\">2024-08-11/17-20</a></strong> to <a href='https://wandb.ai/lakestar/text_spectral_analysis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lakestar/text_spectral_analysis' target=\"_blank\">https://wandb.ai/lakestar/text_spectral_analysis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lakestar/text_spectral_analysis/runs/umrimeso' target=\"_blank\">https://wandb.ai/lakestar/text_spectral_analysis/runs/umrimeso</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wandb Initiated Successfully\n"
     ]
    }
   ],
   "source": [
    "test.wandb_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Configuration\n",
      "--------------------------------------\n",
      "base_model: meta-llama/Llama-2-7b-hf\n",
      "data_path: /root/autodl-tmp/new_version/train_set_fixed.json\n",
      "output_dir: ./Train/Output/2024-08-11/17-20\n",
      "prompt_template_name: alpaca\n",
      "--------------------------------------\n",
      "load_in_8bit: True\n",
      "torch_dtype: torch.float16\n",
      "device_map: auto\n",
      "--------------------------------------\n",
      "lora_r: 16\n",
      "lora_alpha: 32\n",
      "lora_dropout: 0.05\n",
      "lora_target_modules: ['q_proj', 'v_proj']\n",
      "--------------------------------------\n",
      "batch_size: 128\n",
      "micro_batch_size: 4\n",
      "gradient_accumulation_steps: 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<font color=\"red\">num_epochs: 15</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.0003\n",
      "cutoff_len: 256\n",
      "val_set_size: 200\n",
      "train_on_inputs: True\n",
      "add_eos_token: False\n",
      "group_by_length: False\n",
      "resume_from_checkpoint: None\n",
      "ddp: False\n",
      "warmup_steps: 100\n",
      "eval_steps: 20\n",
      "save_steps: 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<font color=\"red\">save_total_limit: 40</font>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "wandb_project: test\n",
      "wandb_run_name: \n",
      "wandb_watch: \n",
      "wandb_log_model: \n",
      "--------------------------------------\n",
      "tokenizer_name: meta-llama/Llama-2-7b-hf\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=1,\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_persistent_workers=False,\n",
       "dataloader_pin_memory=True,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "dispatch_batches=None,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_steps=20,\n",
       "evaluation_strategy=steps,\n",
       "fp16=True,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=32,\n",
       "gradient_checkpointing=False,\n",
       "gradient_checkpointing_kwargs=None,\n",
       "greater_is_better=False,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=False,\n",
       "hub_strategy=every_save,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_inputs_for_metrics=False,\n",
       "include_num_input_tokens_seen=False,\n",
       "include_tokens_per_second=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=0.0003,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=True,\n",
       "local_rank=0,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=./Train/Output/2024-08-11/17-20/runs/Aug11_17-21-53_autodl-container-c9f947bd57-f712e87b,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=10,\n",
       "logging_strategy=steps,\n",
       "lr_scheduler_kwargs={},\n",
       "lr_scheduler_type=linear,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=loss,\n",
       "mp_parameters=,\n",
       "neftune_noise_alpha=None,\n",
       "no_cuda=False,\n",
       "num_train_epochs=15,\n",
       "optim=adamw_torch,\n",
       "optim_args=None,\n",
       "output_dir=./Train/Output/2024-08-11/17-20,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=8,\n",
       "per_device_train_batch_size=4,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=['wandb'],\n",
       "resume_from_checkpoint=None,\n",
       "run_name=2024-08-11/17-20,\n",
       "save_on_each_node=False,\n",
       "save_only_model=False,\n",
       "save_safetensors=True,\n",
       "save_steps=20,\n",
       "save_strategy=steps,\n",
       "save_total_limit=40,\n",
       "seed=42,\n",
       "skip_memory_metrics=True,\n",
       "split_batches=False,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_cpu=False,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=100,\n",
       "weight_decay=0.0,\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_config={'num_epochs' : 15,'learning_rate': 0.0003,'save_total_limit':40}  # 必须这样输入才行\n",
    "Arguments = test.train(**train_config)\n",
    "\n",
    "#Arguments = test.train(My_trainer=MyTrainer, **train_config)   # if you want to change the loss function, you can use this line to change the loss function.\n",
    "test.Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/root/miniconda3/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 10/210 03:49 < 1:35:31, 0.03 it/s, Epoch 0.64/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test.trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
