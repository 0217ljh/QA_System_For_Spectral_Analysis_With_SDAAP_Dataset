{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "sys.path.append('../../')\n",
    "from Train.utils.prompter import Prompter\n",
    "from configs.Fine_tune_config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists('../templates/alpaca.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['callbacks.py',\n",
       " 'finetune.py',\n",
       " 'prompter.py',\n",
       " 'README.md',\n",
       " 'test.ipynb',\n",
       " '__init__.py',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_datetime = datetime.datetime.now()\n",
    "formatted_date = current_datetime.strftime(\"%Y-%m-%d\")\n",
    "formatted_time = current_datetime.strftime(\"%H-%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fine_tune():\n",
    "    def __init__(self, train_data_path,  test_data=None, base_model=None, output_dir=None, **Configs):\n",
    "        # Initialisation Configuration\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "        self.val_data = None\n",
    "        self.prompter = None\n",
    "        for key, value in Configs.items():\n",
    "             setattr(self, str(key), value)\n",
    "        self.base_model ='meta-llama/Llama-2-7b-hf' if base_model is None else base_model\n",
    "        if train_data_path is None:\n",
    "            raise ValueError(\"train_data_path can't be None\")\n",
    "        else:self.train_data_path = train_data_path\n",
    "        self.test_data = test_data\n",
    "        if output_dir is None:\n",
    "            current_datetime = datetime.datetime.now()\n",
    "            current_date = current_datetime.strftime(\"%Y-%m-%d\")\n",
    "            self.output_dir = os.path.join('../Output/', current_date)\n",
    "            if not os.path.exists(self.output_dir):\n",
    "                os.makedirs(self.output_dir)\n",
    "        else: self.output_dir = output_dir\n",
    "        self.gradient_accumulation_steps = self.batch_size // self.micro_batch_size   # 128 // 4 = 32 ,向下取整\n",
    "        self.device_map = \"auto\"\n",
    "        self.world_size = int(os.environ.get(\"WORLD_SIZE\", 1))   # 这个环境变量一般为1，不知道具体有什么用，可能和分卡训练有关。\n",
    "        self.ddp = self.world_size != 1   # ddp一般为False\n",
    "        if self.ddp:\n",
    "            self.device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)}\n",
    "            self.gradient_accumulation_steps = self.gradient_accumulation_steps // self.world_size\n",
    "    \n",
    "    def print_config(self):\n",
    "        print('Current Configuration')\n",
    "        for key, value in self.__dict__.items():\n",
    "            if key =='train_data' or key == 'test_data' or key == 'val_data':\n",
    "                 pass\n",
    "            else:print(key, ' : ', value)\n",
    "\n",
    "    def load_template(self, prompt_template_path = None):\n",
    "        if prompt_template_path is None:\n",
    "            print('Default template : f{self.prompt_template_name}')\n",
    "            self.prompter = Prompter(self.prompt_template_name) # Loading Default Template\n",
    "        else:\n",
    "            print('Loading template : {}'.prompt_template_path)\n",
    "            self.prompt_template_name = prompt_template_path\n",
    "            self.prompter = Prompter(self.prompt_template_name) \n",
    "    \n",
    "    \n",
    "    def load_data(self):\n",
    "        pass\n",
    "        # print('Loading Data')\n",
    "        # self.train_data = pd.read_csv(self.train_data_path)\n",
    "        # if self.test_data is not None:\n",
    "        #     self.test_data = pd.read_csv(self.test_data)\n",
    "        # if self.val_data is not None:\n",
    "        #     self.val_data = pd.read_csv(self.val_data)\n",
    "        # print('Data Loaded Successfully')\n",
    "\n",
    "    def data_preprocess(self):\n",
    "        pass\n",
    "        # print('Data Preprocessing')\n",
    "        # self.train_data = self.train_data.dropna()\n",
    "        # if self.test_data is not None:\n",
    "        #     self.test_data = self.test_data.dropna()\n",
    "        # if self.val_data is not None:\n",
    "        #     self.val_data = self.val_data.dropna()\n",
    "        # print('Data Preprocessing Done')\n",
    "    \n",
    "    def train(self):\n",
    "        pass\n",
    "        # print('Training Started')\n",
    "        # self.model.fit(self.train_data)\n",
    "        # print('Training Done')\n",
    "    \n",
    "    def predict(self):\n",
    "        pass\n",
    "        # print('Prediction Started')\n",
    "        # self.predictions = self.model.predict(self.test_data)\n",
    "        # print('Prediction Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Fine_tune(train_data_path='.\\Dataset\\SET-2024_1_1\\Train_Set\\Train_Set.json',**Configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alpaca'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.prompt_template_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default template : f{self.prompt_template_name}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Can't read templates\\alpaca.json",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_template\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[69], line 40\u001b[0m, in \u001b[0;36mFine_tune.load_template\u001b[1;34m(self, prompt_template_path)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompt_template_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDefault template : f\u001b[39m\u001b[38;5;132;01m{self.prompt_template_name}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompter \u001b[38;5;241m=\u001b[39m \u001b[43mPrompter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_template_name\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Loading Default Template\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading template : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mprompt_template_path)\n",
      "File \u001b[1;32mg:\\make_question\\new_verson\\Train\\utils\\../..\\Train\\utils\\prompter.py:20\u001b[0m, in \u001b[0;36mPrompter.__init__\u001b[1;34m(self, template_name, verbose)\u001b[0m\n\u001b[0;32m     18\u001b[0m file_name \u001b[38;5;241m=\u001b[39m osp\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemplates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemplate_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m osp\u001b[38;5;241m.\u001b[39mexists(file_name):\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt read \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_name) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemplate \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(fp)\n",
      "\u001b[1;31mValueError\u001b[0m: Can't read templates\\alpaca.json"
     ]
    }
   ],
   "source": [
    "test.load_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Configuration\n",
      "prompter  :  None\n",
      "batch_size  :  128\n",
      "micro_batch_size  :  4\n",
      "num_epochs  :  3\n",
      "learning_rate  :  0.0003\n",
      "cutoff_len  :  256\n",
      "val_set_size  :  200\n",
      "lora_r  :  8\n",
      "lora_alpha  :  16\n",
      "lora_dropout  :  0.05\n",
      "lora_target_modules  :  ['q_projv_proj']\n",
      "train_on_inputs  :  True\n",
      "add_eos_token  :  False\n",
      "group_by_length  :  False\n",
      "wandb_project  :  test\n",
      "wandb_run_name  :  \n",
      "wandb_watch  :  \n",
      "wandb_log_model  :  \n",
      "resume_from_checkpoint  :  None\n",
      "prompt_template_name  :  alpaca\n",
      "base_model  :  meta-llama/Llama-2-7b-hf\n",
      "train_data_path  :  .\\Dataset\\SET-2024_1_1\\Train_Set\\Train_Set.json\n",
      "output_dir  :  ../Output/2024-01-05\n",
      "gradient_accumulation_steps  :  32\n",
      "device_map  :  auto\n",
      "world_size  :  1\n",
      "ddp  :  False\n"
     ]
    }
   ],
   "source": [
    "test.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Load_path = {base_model: str = r\"F:\\Model\\HF\\hub\\models--meta-llama--Llama-2-7b-hf\\snapshots\\8cca527612d856d7d32bd94f8103728d614eb852\",\n",
    "train_data_path :str = '.\\Dataset\\SET-2024_1_1\\Train_Set\\Train_Set.json',\n",
    "test_data_path  :str = '.\\Dataset\\SET-2024_1_1\\Test_Set\\Test_Set.json',\n",
    "#train_data_path: str = \"./Dataset/alpaca_data_gpt4.json\"\n",
    "output_dir: str = '.\\Output\\Result2',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128, 'micro_batch_size': 4, 'num_epochs': 3, 'learning_rate': 0.0003, 'cutoff_len': 256, 'val_set_size': 200, 'lora_r': 8, 'lora_alpha': 16, 'lora_dropout': 0.05, 'lora_target_modules': ['q_projv_proj'], 'train_on_inputs': True, 'add_eos_token': False, 'group_by_length': False, 'wandb_project': 'test', 'wandb_run_name': '', 'wandb_watch': '', 'wandb_log_model': '', 'resume_from_checkpoint': None, 'prompt_template_name': 'alpaca', 'base_model': 'meta-llama/Llama-2-7b-hf', 'train_data_path': '.\\\\Dataset\\\\SET-2024_1_1\\\\Train_Set\\\\Train_Set.json', 'test_data': None, 'output_dir': '../Output/2024-01-05'}\n"
     ]
    }
   ],
   "source": [
    "print(test.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印test的所有属性\n",
    "# print(test.__dict__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
